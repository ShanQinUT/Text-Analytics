{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler (Entry Level Luxury forum from Edmunds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import webdriver from selenium\n",
    "from selenium import webdriver\n",
    "chrome_path = r'C:/Users/b0130/Downloads/chromedriver_win32/chromedriver'\n",
    "# prepend it with r because of the backslash characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(soup):\n",
    "    date = []\n",
    "    for element in soup.find_all(class_='MItem DateCreated'):\n",
    "        date.append(element.find('time').text.strip())\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_userid(soup):\n",
    "    userid = []\n",
    "    for element in soup.find_all(class_='Comment'):\n",
    "        userid.append(element.find_all('span')[0].text.strip())\n",
    "    return userid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quote(soup):\n",
    "    cleantext = []\n",
    "    text = soup.find_all('div',{'class':'Message'})\n",
    "    for t in text:\n",
    "        if t.find('blockquote'):\n",
    "            try:\n",
    "                cleantext.append(t.contents[2].strip())\n",
    "            except:\n",
    "                cleantext.append(u\"\")\n",
    "        else:\n",
    "            cleantext.append(t.contents[0].strip()) \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data (url, driver, pages):\n",
    "    date = []\n",
    "    userid = []\n",
    "    cleantext = []\n",
    "    for i in range (pages):\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "        date += get_date(soup)\n",
    "        userid += get_userid(soup)\n",
    "        cleantext += remove_quote(soup)\n",
    "        next_button = soup.find(\"a\", class_=\"Previous Pager-nav\")\n",
    "        url = next_button['href']\n",
    "    return pd.DataFrame(list(zip(date, userid, cleantext)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the Entry Level Luxury forum from Edmunds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p702\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "data = get_data(url, driver, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import webdriver from selenium\n",
    "from selenium import webdriver\n",
    "chrome_path = r'C:/Users/b0130/Downloads/chromedriver_win32/chromedriver'\n",
    "# prepend it with r because of the backslash characters\n",
    "\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_date(soup):\n",
    "    date = []\n",
    "    for element in soup.find_all(class_='MItem DateCreated'):\n",
    "        date.append(element.find('time').text.strip())\n",
    "    return date\n",
    "\n",
    "def get_userid(soup):\n",
    "    userid = []\n",
    "    for element in soup.find_all(class_='Comment'):\n",
    "        userid.append(element.find_all('span')[0].text.strip())\n",
    "    return userid\n",
    "\n",
    "def remove_quote(soup):\n",
    "    cleantext = []\n",
    "    text = soup.find_all('div',{'class':'Message'})\n",
    "    for t in text:\n",
    "        if t.find('blockquote'):\n",
    "            try:\n",
    "                cleantext.append(t.contents[2].strip())\n",
    "            except:\n",
    "                cleantext.append(u\"\")\n",
    "        else:\n",
    "            cleantext.append(t.contents[0].strip()) \n",
    "    return cleantext\n",
    "\n",
    "def get_data (url, driver, pages):\n",
    "    date = []\n",
    "    userid = []\n",
    "    cleantext = []\n",
    "    for i in range (pages):\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "        date += get_date(soup)\n",
    "        userid += get_userid(soup)\n",
    "        cleantext += remove_quote(soup)\n",
    "        next_button = soup.find(\"a\", class_=\"Previous Pager-nav\")\n",
    "        url = next_button['href']\n",
    "    return pd.DataFrame(list(zip(date, userid, cleantext)))\n",
    "\n",
    "url = \"https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p702\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "data = get_data(url, driver, 170)\n",
    "\n",
    "data.to_csv('final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "\n",
    "%pylab inline\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comments are coming in as utf-8 so I am using this code to change it back to ascii\n",
    "def unicodetoascii(text):\n",
    "\n",
    "    TEXT = (text.\n",
    "    \t\treplace('\\xe2\\x80\\x99', \"'\").\n",
    "            replace('\\xc3\\xa9', 'e').\n",
    "            replace('\\xe2\\x80\\x90', '-').\n",
    "            replace('\\xe2\\x80\\x91', '-').\n",
    "            replace('\\xe2\\x80\\x92', '-').\n",
    "            replace('\\xe2\\x80\\x93', '-').\n",
    "            replace('\\xe2\\x80\\x94', '-').\n",
    "            replace('\\xe2\\x80\\x94', '-').\n",
    "            replace('\\xe2\\x80\\x98', \"'\").\n",
    "            replace('\\xe2\\x80\\x9b', \"'\").\n",
    "            replace('\\xe2\\x80\\x9c', '\"').\n",
    "            replace('\\xe2\\x80\\x9c', '\"').\n",
    "            replace('\\xe2\\x80\\x9d', '\"').\n",
    "            replace('\\xe2\\x80\\x9e', '\"').\n",
    "            replace('\\xe2\\x80\\x9f', '\"').\n",
    "            replace('\\xe2\\x80\\xa6', '...').#\n",
    "            replace('\\xe2\\x80\\xb2', \"'\").\n",
    "            replace('\\xe2\\x80\\xb3', \"'\").\n",
    "            replace('\\xe2\\x80\\xb4', \"'\").\n",
    "            replace('\\xe2\\x80\\xb5', \"'\").\n",
    "            replace('\\xe2\\x80\\xb6', \"'\").\n",
    "            replace('\\xe2\\x80\\xb7', \"'\").\n",
    "            replace('\\xe2\\x81\\xba', \"+\").\n",
    "            replace('\\xe2\\x81\\xbb', \"-\").\n",
    "            replace('\\xe2\\x81\\xbc', \"=\").\n",
    "            replace('\\xe2\\x81\\xbd', \"(\").\n",
    "            replace('\\xe2\\x81\\xbe', \")\")\n",
    "\n",
    "                 )\n",
    "    return TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv', sep=',',names=['id', 'date','user','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.index[:1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>September 7</td>\n",
       "      <td>dino001</td>\n",
       "      <td>If they keep it around in next four-five years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>September 7</td>\n",
       "      <td>circlew</td>\n",
       "      <td>The lease rate is the factor that stops me col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>September 8</td>\n",
       "      <td>qbrozen</td>\n",
       "      <td>Yes, the completely noncomparable M2 would bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>September 9</td>\n",
       "      <td>FlightNurse2</td>\n",
       "      <td>Why not a Genesis G70 with a manual?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>September 9</td>\n",
       "      <td>roadburner</td>\n",
       "      <td>Again, the local dealer are hopeless at best(W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         date          user  \\\n",
       "1  0.0  September 7       dino001   \n",
       "2  1.0  September 7       circlew   \n",
       "3  2.0  September 8       qbrozen   \n",
       "4  3.0  September 9  FlightNurse2   \n",
       "5  4.0  September 9    roadburner   \n",
       "\n",
       "                                                text  \n",
       "1  If they keep it around in next four-five years...  \n",
       "2  The lease rate is the factor that stops me col...  \n",
       "3  Yes, the completely noncomparable M2 would bea...  \n",
       "4               Why not a Genesis G70 with a manual?  \n",
       "5  Again, the local dealer are hopeless at best(W...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text field is the comments field\n",
    "#unicodetoascii changes the form from unicoding to regular english\n",
    "#making all the comments lower case\n",
    "#dt = data.iloc[:50]\n",
    "text = data['text']\n",
    "text = text.map(lambda a: unicodetoascii(str(a)))\n",
    "text = text.map(lambda a: a.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found out there are some strange brands in models.csv, so we removed those brands and made the new model list called models_revised.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = pd.read_csv('models.csv', sep=',',names=['brand','model'],encoding='windows-1252')\n",
    "models_revised = pd.read_csv('models_revised.csv', sep=',',names=['brand','model'],encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this text is also in unicode so just replacing one of the symbols with a space \n",
    "#(we can also call the unicodetoascii function here for more robust cleaning)\n",
    "#making the model names lowercase\n",
    "models.model = models['model'].map(lambda x: x.replace('\\xa0', ''))\n",
    "models.model = models['model'].map(lambda x: x.lower())\n",
    "models_revised.model = models_revised['model'].map(lambda x: x.replace('\\xa0', ''))\n",
    "models_revised.model = models_revised['model'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary {model: brand}\n",
    "#this will be used when locating when the model is written, and replacing it to the brand name\n",
    "brand_dict = {}\n",
    "for i in range(len(models_revised)):\n",
    "    brand_dict[models_revised['model'][i]] = models_revised['brand'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replace(match):\n",
    "    return brand_dict[match.group(0)]\n",
    "\n",
    "text = text.map(lambda x: re.sub('|'.join(r'%s' % re.escape(s) for s in brand_dict), \n",
    "        replace, x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all of the unique/different brand names\n",
    "brand = list(set(models_revised.brand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#findall: takes each comment separately, finds every time any brand is mentioned, and adds it to the master list\n",
    "#set(ls): this makes sure that even if the brand is mentioned more than once, it is only recorded once\n",
    "master_list = []\n",
    "\n",
    "def findall(w):\n",
    "    ls = []\n",
    "    ls = [e for e in brand for i in w.split() if e in i] #this line finds where the brand is mentioned in the comment (could be\n",
    "    # of any format: ex. \"honda.\"| \"honda's\" | \"honda-and\" | etc., and records it as just \"honda\")\n",
    "    ls = list(set(ls))\n",
    "    master_list.append(ls) #this stores all the mentions of every comment we have\n",
    "text.map(findall)\n",
    "\n",
    "count_list = sum(master_list)\n",
    "\n",
    "brand_mention_doc = master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmw           532\n",
       "toyota        504\n",
       "audi          460\n",
       "honda         246\n",
       "acura         217\n",
       "chrysler      150\n",
       "volkswagen    121\n",
       "infiniti      106\n",
       "hyundai       103\n",
       "cadillac       98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_series = pd.Series(count_list).value_counts()\n",
    "count_series[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 brands by frequency is BMW, Toyota, Audi, Honda, Acura, Chrysler, Volkswagen, Infiniti, Hyundai and Cadillac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list = list(filter(None,master_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Lift calculation. (If two cars never occur together when calculating lift, we make the co_occur =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur(car1, car2):\n",
    "    freq = 0\n",
    "    for i in range(len(master_list)):\n",
    "        if (car1 in master_list[i]) & (car2 in master_list[i]):\n",
    "            freq += 1\n",
    "    return freq\n",
    "\n",
    "def lift(car1, car2):\n",
    "    if float(co_occur(car1, car2)) != 0:\n",
    "        return (float(len(text)) * float(co_occur(car1, car2))) / (float(count_series.loc[car1]) * float(count_series.loc[car2]))\n",
    "    else:\n",
    "        return (float(len(text))) / (float(count_series.loc[car1]) * float(count_series.loc[car2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bmw', 'toyota') 1.5777949337629789\n",
      "('bmw', 'audi') 1.999476953252697\n",
      "('bmw', 'honda') 1.713643865761966\n",
      "('bmw', 'acura') 1.2803870274765254\n",
      "('bmw', 'chrysler') 0.5748496240601504\n",
      "('bmw', 'volkswagen') 0.8709842788790157\n",
      "('bmw', 'infiniti') 1.4461625762519505\n",
      "('bmw', 'hyundai') 1.7673370319001387\n",
      "('bmw', 'cadillac') 1.8575072886297377\n",
      "('toyota', 'audi') 1.8027691511387163\n",
      "('toyota', 'honda') 2.795489740611692\n",
      "('toyota', 'acura') 1.2583113890717577\n",
      "('toyota', 'chrysler') 2.2248809523809525\n",
      "('toyota', 'volkswagen') 2.0059031877213696\n",
      "('toyota', 'infiniti') 1.8127246181491465\n",
      "('toyota', 'hyundai') 2.061893203883495\n",
      "('toyota', 'cadillac') 2.063896987366375\n",
      "('audi', 'honda') 1.6215270413573701\n",
      "('audi', 'acura') 2.1446002805049087\n",
      "('audi', 'chrysler') 1.699\n",
      "('audi', 'volkswagen') 4.029249011857708\n",
      "('audi', 'infiniti') 4.285828547990156\n",
      "('audi', 'hyundai') 1.7212325875897003\n",
      "('audi', 'cadillac') 2.035181898846495\n",
      "('honda', 'acura') 5.346970889063729\n",
      "('honda', 'chrysler') 5.939593495934959\n",
      "('honda', 'volkswagen') 2.7397702076194315\n",
      "('honda', 'infiniti') 1.7592038656235618\n",
      "('honda', 'hyundai') 1.8104428131659958\n",
      "('honda', 'cadillac') 1.4799651567944252\n",
      "('acura', 'chrysler') 7.672903225806452\n",
      "('acura', 'volkswagen') 1.164717979967247\n",
      "('acura', 'infiniti') 5.096556821145987\n",
      "('acura', 'hyundai') 1.368260927922688\n",
      "('acura', 'cadillac') 1.9174268785855355\n",
      "('chrysler', 'volkswagen') 0.5616528925619835\n",
      "('chrysler', 'infiniti') 0.9616981132075472\n",
      "('chrysler', 'hyundai') 0.9897087378640776\n",
      "('chrysler', 'cadillac') 1.040204081632653\n",
      "('volkswagen', 'infiniti') 0.3973959145485732\n",
      "('volkswagen', 'hyundai') 2.86279386985477\n",
      "('volkswagen', 'cadillac') 1.2895091921065946\n",
      "('infiniti', 'hyundai') 0.9336874885510167\n",
      "('infiniti', 'cadillac') 2.453311513284559\n",
      "('hyundai', 'cadillac') 1.5148603130572618\n"
     ]
    }
   ],
   "source": [
    "top_10_brand = list(count_series[:10].index.values)\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "for combo in combinations(list(count_series[:10].index.values), 2):\n",
    "    print(combo,lift(combo[0],combo[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define distance to be the reciprocal of the lift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "for car1 in top_10_brand:\n",
    "    group_dist=[]\n",
    "    for car2 in top_10_brand:\n",
    "        if car1 != car2:\n",
    "            group_dist.append(1/lift(car1, car2))\n",
    "        elif car1 == car2:\n",
    "            group_dist.append(0.0)\n",
    "    dist_list.append(group_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b0130\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\manifold\\mds.py:411: UserWarning: The MDS API has changed. ``fit`` now constructs an dissimilarity matrix from data. To use a custom dissimilarity matrix, set ``dissimilarity='precomputed'``.\n",
      "  warnings.warn(\"The MDS API has changed. ``fit`` now constructs an\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2)\n",
    "pos = mds.fit(dist_list).embedding_\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pos[:, 0], pos[:, 1], color='turquoise')\n",
    "for i, txt in enumerate(top_10_brand):\n",
    "    ax.annotate(txt, (pos[:, 0][i], pos[:, 1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What insights can you offer brand managers from your analysis in Task A (choose two brands that you can offer the most interesting/useful insights for)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the MDS map we can find that the Honda and Toyota is next to each other, which means that those two brands are brought up together frequently. Honda and Toyota are Shoppers looking for an affordable and reliable new vehicle have probably considered Toyota and Honda are very competitive with each other in the car market. When people are looking for an affordable and reliable new vehicle, they will probably consider Toyota and Honda same time. Both Honda and Toyota are facing the market segmentation with the same requirement on pricing, safety and reliability. Also, people are more likely to cross-shopping these two brands. In that case, it is reasonable that Honda and Toyota are mentioned together frequently and compared with each other. \n",
    "\n",
    "The advice we are offering to the brand manager of these two brands is that their campaign should emphasize more on the comparison of these two products. In that case, it could not only helps the brand generate more publicity but also differentiate the brand from each other and highlight the special and proprietary of the brand. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pick the 5 attributes, we decided to use Bag of Words to find the most frequent words, and then divide them into 5 categories. We removed the stopwords and punctuation, and then lemmatized all the words. Lastly, we observed the frequency table and pick the 5 attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess(x):\n",
    "    lowercase= x.lower()\n",
    "    for p in punctuation:\n",
    "        lowercase = lowercase.replace(p,'')\n",
    "    return lowercase\n",
    "\n",
    "token = text.map(preprocess).map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [if, they, keep, it, around, in, next, fourfiv...\n",
       "2    [the, lease, rate, is, the, factor, that, stop...\n",
       "3    [yes, the, completely, noncomparable, m2, woul...\n",
       "4         [why, not, a, hyundai, g70, with, a, manual]\n",
       "5    [again, the, local, dealer, are, hopeless, at,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_sentence = [] \n",
    "\n",
    "def remove_stopwords(x):\n",
    "    for w in x: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "token.map(remove_stopwords)\n",
    "pos_tagging = nltk.pos_tag(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('keep', 'VB'),\n",
       " ('around', 'IN'),\n",
       " ('next', 'JJ'),\n",
       " ('fourfive', 'JJ'),\n",
       " ('years', 'NNS')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagging[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "l = []\n",
    "for word, tag in pos_tagging:\n",
    "    wntag = get_wordnet_pos(tag)\n",
    "    if wntag is None:\n",
    "        lemma = lemmatizer.lemmatize(word)\n",
    "        l.append(lemma)\n",
    "    else:\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wntag) \n",
    "        l.append(lemma)\n",
    "\n",
    "words_value_counts = pd.Series(l).value_counts()\n",
    "words_value_counts.to_csv('Word_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the words frequency table, we picked our 5 attributes: Size, Performance, Design, Price and Duration. \n",
    "We picked several words to represent the attributes. \n",
    "\n",
    "Size:\n",
    "1. Big\n",
    "2. Small\n",
    "\n",
    "Performance:\n",
    "1. Drive\n",
    "2. Performance \n",
    "3. Power \n",
    "4. Sound\n",
    "5. Mpg\n",
    "6. Speed \n",
    "\n",
    "Design:\n",
    "1. Sports\n",
    "2. Look \n",
    "3. Old \n",
    "4. Interior \n",
    "5. Seat \n",
    "6. Manual\n",
    "7. Color \n",
    "\n",
    "Price:\n",
    "1. Price\n",
    "2. Cost \n",
    "3. Luxury \n",
    "4. Money \n",
    "5. Cheap \n",
    "6. Value \n",
    "\n",
    "Duration:\n",
    "1. Years\n",
    "2. Miles \n",
    "3. Old \n",
    "4. Warranty \n",
    "5. Mileage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use these word to represent 5 attributes and calculate the lift with top 5 car brands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos = token.map(nltk.pos_tag) ## Tokennize all text in order to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_msg(x):\n",
    "    msg_l = []\n",
    "    for word, tag in x:\n",
    "        wntag = get_wordnet_pos(tag)\n",
    "        if wntag is None:\n",
    "            lemma = lemmatizer.lemmatize(word)\n",
    "            msg_l.append(lemma)\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wntag) \n",
    "            msg_l.append(lemma)\n",
    "    return msg_l\n",
    "\n",
    "token_lemm = pd.Series(token_pos).map(lemm_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sring(x):\n",
    "    return ' '.join(x)\n",
    "text_lemm = token_lemm.map(list_to_sring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = pd.read_csv('att.csv', sep = ',',names=['attribute','word'], encoding='windows-1252')\n",
    "att.word = att['word'].map(lambda x: x.replace('\\xa0', ''))\n",
    "att.word = att['word'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_dict = {}\n",
    "for i in range(len(att)):\n",
    "    att_dict[att['word'][i]] = att['attribute'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_att(x):\n",
    "    return att_dict[x.group(0)]\n",
    "\n",
    "text_att = text_lemm.map(lambda x: re.sub('|'.join(r'%s' % re.escape(s) for s in att_dict), \n",
    "        replace_att, x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_brand = list(count_series[:5].index.values)\n",
    "attribute_list = list(att['attribute'].unique())\n",
    "co_occur_list = top_5_brand + attribute_list\n",
    "master_list_att = []\n",
    "\n",
    "def findall_att(w):\n",
    "    ls = []\n",
    "    ls = [e for e in co_occur_list for i in w.split() if e in i]\n",
    "    ls = list(set(ls))\n",
    "    master_list_att.append(ls)\n",
    "text_att.map(findall_att)\n",
    "\n",
    "#master_list_att = list(filter(None,master_list_att))\n",
    "count_list_att = sum(master_list_att)\n",
    "count_series_att = pd.Series(count_list_att).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration       1022\n",
       "performance     759\n",
       "price           611\n",
       "design          598\n",
       "bmw             532\n",
       "toyota          504\n",
       "audi            460\n",
       "size            276\n",
       "honda           246\n",
       "acura           217\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_series_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur_att(car, att):\n",
    "    freq = 0\n",
    "    for i in range(len(master_list_att)):\n",
    "        if (car in master_list_att[i]) & (att in master_list_att[i]):\n",
    "            freq += 1\n",
    "    return freq\n",
    "\n",
    "def lift_att(car, att):\n",
    "    return (float(len(text_att)) * float(co_occur_att(car, att))) / (float(count_series_att.loc[car]) * float(count_series_att.loc[att]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmw size 1.9092227852239294\n",
      "bmw performance 1.7040996760676395\n",
      "bmw design 1.8584881937284683\n",
      "bmw price 1.991432140088355\n",
      "bmw duration 1.7905459588305401\n",
      "toyota size 2.2717822636300897\n",
      "toyota performance 2.025283894849112\n",
      "toyota design 2.1477643733078517\n",
      "toyota price 2.019308705478918\n",
      "toyota duration 1.969183906439288\n",
      "audi size 2.087618147448015\n",
      "audi performance 1.8832359511943633\n",
      "audi design 2.316144394358005\n",
      "audi price 1.614007685191774\n",
      "audi duration 1.5070258657364077\n",
      "honda size 2.7025450689289503\n",
      "honda performance 2.1292779330955365\n",
      "honda design 2.148176849661473\n",
      "honda price 1.8990060277034848\n",
      "honda duration 2.0476230251539307\n",
      "acura size 2.297786014826688\n",
      "acura performance 1.7639569406750333\n",
      "acura design 2.003198064207882\n",
      "acura price 1.8452487800463093\n",
      "acura duration 1.9535427958191673\n"
     ]
    }
   ],
   "source": [
    "for brand in top_5_brand:\n",
    "    for attribute in attribute_list:\n",
    "        print(brand, attribute, lift_att(brand, attribute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size\n",
    "For size, Honda is the brand most strongly associated with the attribute. \n",
    "### Performance\n",
    "Honda is also the brand most strongly associated with performance. \n",
    "### Design\n",
    "Audi is the brand most strongly associated with design. It is not a surprise since Audi is very proud of their car design. \n",
    "### Price\n",
    "When it comes to price, people tend to talk about Toyota more than other brands. \n",
    "### Duration\n",
    "Honda is again the brand most strongly associated with duration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMW:\n",
    "Surprisingly, BMW has low lift on most of the 5 attributes except price. It can be caused by the users on online-forum are younger and couldn't afford a BMW.\n",
    "### Toyota:\n",
    "By having a comparatively high lift on all attributes, it seems that Toyota serves as a benchmark in discussions on attributes. People like to compare the dicussion between buying a car under dicussion with buying a Toyota. Which suggest the prevalence of Toyota because of the relatively good quality given the price.\n",
    "### Audi:\n",
    "Having the highest lift on design among the five brands. Audi has an advantage on attracting people's eyeballs by how the car looks.\n",
    "### Honda: \n",
    "It seems that people are more concerned on the size of Honda's car and how long could the car be drive with little maintenance. Therefore, size and duration are the attributes Honda needs to emphasize on its commercials.\n",
    "### Acura:\n",
    "People talk more about Acura's size and design, which seems to be the strength of the brand. However, Acura should notice Edmunds user are talking less about the Acura's performance, which could be its weakness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task E, we first define a list of \"aspiring words\". Next, we searched if any of the \"aspiring words\" appear in the lemmatized, stop word removed text. Then, we find three words in both the front and the end of the \"aspiring word\" found, and check if any brand names in these six words. If brand name found, we found an incidence of expressing asipiration to a brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import snowball\n",
    "import string\n",
    "stop_w = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    return([w for w in tokens if not w in stop_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words from the token of lemmantized comments\n",
    "token_lem_s_removed = token_lemm.map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspiring_words = [\"want\", \"dream\", \"hope\", \"wish\", \"aspire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_aspiring = []\n",
    "for index, brand_mentioned in enumerate(brand_mention_doc):\n",
    "    \n",
    "    #for each text, create an dictionary of mentioned {brand : list of asipiring words} \n",
    "    brand_attribute_dict = {}\n",
    "    if brand_mentioned:\n",
    "        for word_index, word in enumerate(token_lem_s_removed.iloc[index]):\n",
    "            \n",
    "            if word in aspiring_words:\n",
    "                #This creates a list of length 7 having the attribute word in the midle\n",
    "                vicinity_word_list = token_lem_s_removed.iloc[index][word_index-3 : word_index+4] \n",
    "                for brand in brand_mentioned:\n",
    "                    \n",
    "                    if brand in vicinity_word_list:\n",
    "                        #Find the index of the brand in our text token list\n",
    "                        brand_index = vicinity_word_list.index(brand)\n",
    "                        #Check if there is period between found aspiration word and brand\n",
    "                        if (brand_index > 3 ) and (\".\" in vicinity_word_list[3 : brand_index]):\n",
    "                            continue\n",
    "                        elif (brand_index < 3) and (\".\" in vicinity_word_list[brand_index : 3]):\n",
    "                            continue\n",
    "                        else:\n",
    "                            if brand not in brand_attribute_dict:\n",
    "                                brand_attribute_dict[brand] = [word]\n",
    "                            else:\n",
    "                                brand_attribute_dict[brand].append(word)\n",
    "                                                                                      \n",
    "    master_list_aspiring.append(brand_attribute_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'honda': ['wish']},\n",
       " {'cadillac': ['want']},\n",
       " {'kia': ['want']},\n",
       " {'kia': ['want'], 'hyundai': ['want']},\n",
       " {'kia': ['hope']}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_list_aspiring_f = list(filter(None,master_list_aspiring))\n",
    "master_list_aspiring_f[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the found pairs of brand and aspiration words to Pandas Series \n",
    "brands_aspire_count_dict = {}\n",
    "for i in master_list_aspiring_f:\n",
    "    for j in i.keys():\n",
    "        if j not in brands_aspire_count_dict:\n",
    "            brands_aspire_count_dict[j] = 1\n",
    "        else:\n",
    "            brands_aspire_count_dict[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmw         11\n",
       "audi         7\n",
       "toyota       6\n",
       "infiniti     5\n",
       "honda        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(brands_aspire_count_dict).sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, the most aspirational brand on Edmunds is BMW. However, we can find from the lift analysis in Task C, people aren't talking about BMW's car attributes a lot. Which implicates BMW has formed a good image among Edmunds users, but has created little surprise and discussion on its car attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
